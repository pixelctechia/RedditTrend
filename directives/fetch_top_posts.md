# Diretiva: Buscar Top 10 Posts por Engajamento ‚Äî Reddit

## Objetivo

Coletar os **100 posts mais recentes** dos subreddits configurados, filtrar os publicados na **√∫ltima semana**, calcular um **score de engajamento** ponderado e selecionar os **10 posts com maior engajamento** de cada subreddit. O dashboard suporta **dois modos de visualiza√ß√£o**: "Top Relevantes" (ranking por engajamento) e "Mais Recentes" (10 posts mais novos com filtros de tempo: dia/semana/m√™s). Gerar artigos Markdown individuais, dashboard web interativo e exportar para Google Sheets.

## Entradas

| Vari√°vel              | Fonte  | Descri√ß√£o                                                |
|-----------------------|--------|----------------------------------------------------------|
| `TARGET_SUBREDDITS`   | `.env` | Subreddits alvo, separados por v√≠rgula (`n8n,automation`) |
| `FETCH_LIMIT`         | `.env` | N¬∫ de posts recentes a buscar por subreddit (default: 100)|
| `TOP_N`               | `.env` | N¬∫ de top posts a selecionar por subreddit (default: 10)  |
| `PERIOD_DAYS`         | `.env` | Janela de tempo em dias (default: 7 = √∫ltima semana)       |
| `WEIGHT_SCORE`        | `.env` | Peso dos upvotes no c√°lculo de engajamento (default: 1.0)  |
| `WEIGHT_COMMENTS`     | `.env` | Peso dos coment√°rios (default: 2.0)                        |
| `WEIGHT_RATIO`        | `.env` | Peso do upvote_ratio (default: 50.0)                       |

## Score de engajamento

A f√≥rmula para ranquear posts por relev√¢ncia e engajamento √©:

```
engagement = (score √ó WEIGHT_SCORE) + (num_comments √ó WEIGHT_COMMENTS) + (upvote_ratio √ó WEIGHT_RATIO)
```

**Racional dos pesos:**
- **Coment√°rios (√ó2.0):** indicam discuss√£o real ‚Äî engagement mais profundo que um simples upvote
- **Score (√ó1.0):** base de popularidade (upvotes - downvotes)
- **Upvote ratio (√ó50.0):** premia posts com aprova√ß√£o consistente da comunidade (ex: 0.95 = 95%)

## Ferramentas / Scripts

### Passo 1: Buscar e ranquear posts
**Script:** `execution/fetch_reddit_posts.py`

- Usa endpoints p√∫blicos do Reddit (sem autentica√ß√£o)
- Para cada subreddit em `TARGET_SUBREDDITS`:
  1. Busca at√© `FETCH_LIMIT` posts do endpoint `/r/{sub}/new` (com pagina√ß√£o)
  2. Filtra apenas os criados nos √∫ltimos `PERIOD_DAYS` dias
  3. Calcula `engagement_score` e seleciona os N com maior score
- Salva:
  - `.tmp/raw_posts.json` ‚Äî todos os posts brutos coletados
  - `.tmp/top_posts.json` ‚Äî somente os top N selecionados

### Passo 2: Formatar dados
**Script:** `execution/format_posts.py`

- L√™ `.tmp/top_posts.json` e `.tmp/raw_posts.json`
- Gera um JSON limpo com os campos:
  - `rank`, `subreddit`, `title`, `score`, `num_comments`, `upvote_ratio`, `engagement_score`, `author`, `url`, `permalink`, `selftext`, `flair`, `created_at`
- Salva em `.tmp/formatted_posts.json` (top N por engajamento)
- Salva em `.tmp/formatted_all_posts.json` (TODOS os posts ‚Äî para modo "Mais Recentes")
- Gera resumo leg√≠vel com tabela em `.tmp/summary.md`

### Passo 3: Gerar artigos Markdown
**Script:** `execution/generate_articles.py`

- L√™ `.tmp/formatted_posts.json`
- Para cada post, gera um arquivo `.md` com:
  - Frontmatter YAML (metadados completos)
  - T√≠tulo + ranking + data
  - Resumo autom√°tico (primeiras frases)
  - Conte√∫do completo do post
  - Tabela de m√©tricas de engajamento + barra visual
  - Se√ß√£o de cr√©ditos atribuindo ao Reddit com link original
- Organiza em pastas por subreddit: `.tmp/articles/{sub}/{slug}.md`
- Gera √≠ndice geral: `.tmp/articles/index.md`

### Passo 4: Gerar dashboard web
**Script:** `execution/generate_app.py`

- L√™ `.tmp/formatted_posts.json`, `.tmp/formatted_all_posts.json`, `.env` e logs
- Gera app HTML autocontido com:
  - Dashboard com tabs por subreddit e stat cards
  - **Modo "üèÜ Top Relevantes"** ‚Äî ranking por engajamento (padr√£o)
  - **Modo "üïê Mais Recentes"** ‚Äî 10 posts mais novos com filtros de tempo:
    - **24h** ‚Äî √∫ltimas 24 horas
    - **Semana** ‚Äî √∫ltimos 7 dias
    - **M√™s** ‚Äî √∫ltimos 30 dias
  - P√°gina Posts (tabela comparativa geral)
  - P√°gina Trends (gr√°ficos de barras CSS)
  - P√°gina Configura√ß√µes (par√¢metros do .env)
  - P√°gina Logs (hist√≥rico de execu√ß√µes)
  - **Bot√£o "‚ûï Importar Post"** no topbar para buscar posts por URL e adicionar novas comunidades
- Sempre retorna exatamente **10 posts** por subreddit no modo ativo
- Salva em `.tmp/app.html`

### Passo 4b (Opcional): Servidor local
**Script:** `execution/server.py`

- Serve o dashboard em `http://localhost:5050`
- Fornece API para:
  - `GET /api/fetch-post?url=...` ‚Äî busca dados de um post do Reddit por URL
  - `POST /api/add-community` ‚Äî adiciona subreddit ao `TARGET_SUBREDDITS` no `.env`
  - `GET /api/communities` ‚Äî lista comunidades registradas
- Permite importar posts e adicionar comunidades **diretamente pelo dashboard**
- Usa `ThreadingHTTPServer` para requests concorrentes

### Passo 5 (Opcional): Exportar para Google Sheets
**Script:** `execution/export_to_sheets.py`

- L√™ `.tmp/formatted_posts.json`
- Insere os dados na planilha configurada em `GOOGLE_SHEET_ID`
- Requer `credentials.json` e `token.json` v√°lidos

## Sa√≠das

| Arquivo                             | Tipo           | Descri√ß√£o                                    |
|-------------------------------------|----------------|----------------------------------------------|
| `.tmp/raw_posts.json`               | Intermedi√°rio  | Todos os posts recentes coletados            |
| `.tmp/top_posts.json`               | Intermedi√°rio  | Top N posts por engajamento                  |
| `.tmp/formatted_posts.json`         | Intermedi√°rio  | Top N formatados e limpos                    |
| `.tmp/formatted_all_posts.json`     | Intermedi√°rio  | TODOS os posts formatados (modo Recentes)    |
| `.tmp/summary.md`                   | Intermedi√°rio  | Resumo leg√≠vel com tabela                    |
| `.tmp/articles/{sub}/{slug}.md`     | Entreg√°vel     | Artigo Markdown por post                     |
| `.tmp/articles/index.md`            | Entreg√°vel     | √çndice geral de artigos                      |
| `.tmp/app.html`                     | Entreg√°vel     | Dashboard web interativo                     |
| `.tmp/logs/dashboard.html`          | Entreg√°vel     | Dashboard de logs de execu√ß√£o                |
| Google Sheets                       | Entreg√°vel     | Planilha atualizada com top posts            |

## Casos de borda

- **Subreddit inexistente/privado:** API retorna 404/403 ‚Üí logar aviso e pular
- **Menos de 5 posts na janela de tempo:** retornar o que houver, sem erro
- **Rate limit da API:** Reddit ‚âà60 req/min ‚Üí respeitar header `X-Ratelimit-Remaining` + delay de 0.5s entre p√°ginas
- **Credenciais inv√°lidas:** mensagem clara e exit
- **Sem internet:** capturar ConnectionError e retornar posts coletados at√© o momento
- **Posts duplicados entre p√°ginas:** o endpoint `/new` pagina com cursor `after`, sem duplicatas

## Aprendizados

_(Atualizar conforme novos comportamentos forem descobertos)_

- Endpoints p√∫blicos do Reddit (`/r/{sub}/new.json`) funcionam sem autentica√ß√£o OAuth2
- O endpoint `/r/{sub}/new` retorna max 100 posts por request; usar `after` para paginar
- O endpoint `/r/{sub}/top` n√£o serve para o caso de uso ‚Äî ele ranqueia por score, n√£o por engajamento customizado
- `upvote_ratio` √© um float entre 0 e 1 (0.95 = 95% de upvotes)
- User-Agent personalizado evita bloqueios por rate limiting
- `link_flair_text` pode ser √∫til para categorizar posts (ex: "Question", "Show off", "Help")
- Posts sem `selftext` (links/imagens) recebem aviso no artigo Markdown
- Slugs dos arquivos truncados a 60 chars para evitar problemas no filesystem
- O pipeline completo gera ~20 artigos em menos de 1 segundo
- O modo "Mais Recentes" filtra client-side a partir de `formatted_all_posts.json`, sem necessidade de re-fetch do Reddit
- `formatted_all_posts.json` inclui campo `created_utc` (timestamp Unix) para filtragem precisa por tempo
- O toggle de modo e os filtros de tempo s√£o animados com transi√ß√µes CSS para UX fluida
- Sempre retorna exatamente 10 posts independente do modo selecionado (ou menos se n√£o houver dados suficientes)
- O servidor local (`server.py`) permite buscar posts por URL e adicionar comunidades sem editar c√≥digo
- Comunidades adicionadas via dashboard s√£o persistidas no `.env` automaticamente
- Ao adicionar comunidade, os posts s√≥ aparecem ap√≥s re-executar o pipeline
- Quando aberto como `file://`, o dashboard consegue buscar posts (CORS), mas precisa do servidor para adicionar comunidades e resolver share links
- URLs do Reddit t√™m v√°rios formatos: `/r/sub/comments/id/slug/` (post), `/r/sub/s/shortId` (share do app), `redd.it/id` (curto), `/r/sub/` (subreddit ‚Äî n√£o √© post)
- Share links (`/r/sub/s/id`) s√£o redirects que precisam ser resolvidos pelo servidor (seguir redirect) antes de extrair o post
- **CUIDADO COM F-STRINGS PYTHON + JAVASCRIPT:** `\n` em f-strings Python √© interpretado como newline literal. Para gerar regex `/\n/g` no JS, usar `\\\\n` (4 backslashes). Para `new RegExp('\\w')`, cada `\` extra precisa de `\\` no f-string. Sempre verificar o HTML de sa√≠da com `cat -A` para confirmar contagem de backslashes

## Pipeline Completo

```bash
# 1. Buscar posts do Reddit
python execution/fetch_reddit_posts.py

# 2. Formatar dados
python execution/format_posts.py

# 3. Gerar artigos Markdown
python execution/generate_articles.py

# 4. Gerar dashboard web
python execution/generate_app.py

# 5. (Opcional) Servir via servidor local (habilita import de posts)
python execution/server.py

# 6. (Opcional) Ver logs
python execution/view_logs.py
```
